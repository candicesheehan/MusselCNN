{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Copy of 3_VIA_to_RetinaNet_subsetted.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/candicesheehan/MusselCNN/blob/main/Mussel_3_VIA_to_RetinaNet_subsetted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWws_Zmzl2U0"
      },
      "source": [
        "# Subset and convert VIA annotations CSV file to RetinaNet CSV format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adbbeiaql2VD"
      },
      "source": [
        "**Before running this script, make sure that your Google Drive folder contains all of the tiles and the `spatial_data.json` that you created (step 1), and the annotations `csv` that you exported from VIA (step 2).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GgYkvC1l2VD"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/candicesheehan/MusselCNN/blob/master/3_VIA_to_RetinaNet_subsetted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "<center> Be sure to update this hyperlink above if you clone and want to point to a different GitHub </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L18dIkUTl2VD"
      },
      "source": [
        "### Connect to our Google Drive folder and pull `csv` and `json` files\n",
        "Note: when you run this it will give you a link that you must click. You must give Google some permissions, then copy a code into a box that comes up in the output section of this code.\n",
        "\n",
        "If customizing this code, you will need to point the `drive_folder` variable to a URL for your shared google drive folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtI8Tc28l2VE"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "import os, json, csv\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('VIA_annotations')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "\n",
        "# set variable to the destination google drive folder you want to pull from\n",
        "drive_folder = 'https://drive.google.com/drive/folders/1INuRNVKvKMy8L_Nb6lmoVbyvScWK0-0D'\n",
        "\n",
        "# this bit points the code to that google drive folder\n",
        "pointer = str(\"'\" + drive_folder.split(\"/\")[-1] + \"'\" + \" in parents\")\n",
        "\n",
        "file_list = drive.ListFile({'q': pointer}).GetList()\n",
        "\n",
        "# this bit pulls all csv and json files from the directory specified above\n",
        "for f in file_list:\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  if fname.endswith(\".json\") or fname.endswith(\".csv\"):\n",
        "    f_ = drive.CreateFile({'id': f['id']})\n",
        "    f_.GetContentFile(fname)\n",
        "    print(\"Pulled file: \" + fname)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBL3WNA6l2VE"
      },
      "source": [
        "### Set up the python environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIIq8rFPl2VF"
      },
      "source": [
        "# import necessary modules\n",
        "import os, csv, random, json\n",
        "\n",
        "# set pseudo-random values for replicability\n",
        "random.seed(1)\n",
        "\n",
        "# use this variable to set input directory\n",
        "input_dir = local_download_path\n",
        "\n",
        "# use this variable to set output directory\n",
        "output_dir = 'RetinaNet_annotations'\n",
        "\n",
        "# create the directory if it doesn't already exist\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfrFEWZJTBva"
      },
      "source": [
        "### Identify necessary files from among files in the input directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxK-jdv2RVkC"
      },
      "source": [
        "annotations_file = []\n",
        "spatial_data_file = []\n",
        "\n",
        "for fname in os.listdir(input_dir):\n",
        "  if fname.endswith(\".csv\"): \n",
        "    annotations_candidate = \"{i}/{f}\".format(i=input_dir, f=fname)\n",
        "    with open(annotations_candidate, \"r\") as f:\n",
        "      if next(csv.reader(f, delimiter=\",\"))[0:3] == ['filename', 'file_size', 'file_attributes']:\n",
        "        annotations_file = annotations_candidate\n",
        "      else: continue\n",
        "\n",
        "  if fname.endswith(\".json\"):\n",
        "    spatial_data_candidate = \"{i}/{f}\".format(i=input_dir, f=fname)\n",
        "    with open(spatial_data_candidate) as f:\n",
        "      try:\n",
        "        image_list = list(json.load(f)[\"tile_pointers\"][\"image_locations\"].keys())\n",
        "        spatial_data_file = spatial_data_candidate\n",
        "      except: continue\n",
        "\n",
        "if annotations_file == []:\n",
        "  raise Exception(\"VIA annotations file not found\")\n",
        "elif spatial_data_file == []:\n",
        "  raise Exception(\"tile spatial data file not found\")\n",
        "\n",
        "print(\"annotations file identified as \" + annotations_file)\n",
        "print(\"tile data file identified as \" + spatial_data_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eheLKPfBl2VF"
      },
      "source": [
        "### Shuffle and split images into 3 datasets: Training, Testing, Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt_McLbfl2VF"
      },
      "source": [
        "# create a list of tiles from our tile spatial data json\n",
        "with open(spatial_data_file) as f:\n",
        "    image_list = list(json.load(f)[\"tile_pointers\"][\"image_locations\"].keys())\n",
        "\n",
        "# shuffle the image list randomly and get total count\n",
        "random.shuffle(image_list)\n",
        "total_count = len(image_list)\n",
        "\n",
        "# set indices for breaking up the total dataset into TTV parts\n",
        "test_fraction, valid_fraction, train_fraction = 0.1, 0.04, 0.86\n",
        "\n",
        "# spit error if the math don't add up\n",
        "if (sum([test_fraction, valid_fraction, train_fraction]) != 1.0):\n",
        "   raise Exception(\"fractions should add up to 1\")\n",
        "\n",
        "test_index = int(total_count * test_fraction)\n",
        "valid_index = int(total_count * (test_fraction + valid_fraction))\n",
        "\n",
        "# use indices to break up dataset into the three parts\n",
        "test_dataset, valid_dataset, train_dataset = image_list[:test_index], image_list[test_index:valid_index], image_list[valid_index:]\n",
        "print(len(test_dataset), len(valid_dataset), len(train_dataset))\n",
        "\n",
        "# spit out CSV listing the image subsets\n",
        "subset_list = []\n",
        "for row in test_dataset:\n",
        "        subset_list.append([row, \"testing\"])\n",
        "for row in valid_dataset:\n",
        "        subset_list.append([row, \"validation\"])\n",
        "for row in train_dataset:\n",
        "        subset_list.append([row, \"training\"])\n",
        "with open(output_dir + '/subset_list.csv', 'w', newline='') as fp:\n",
        "    writer = csv.writer(fp)\n",
        "    writer.writerows(subset_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoMTsew-l2VF"
      },
      "source": [
        "### Reformat annotations from VIA to RetinaNet format\n",
        "The following loop pulls each annotation, line-by-line, from the VIA exported CSV, extracts the necessary information, reformats it into the format that RetinaNet requires (https://github.com/fizyr/keras-retinanet#annotations-format), then reassembles a new CSV line-by-line that RetinaNet can receive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "DQ2btGJRl2VG"
      },
      "source": [
        "# Create blank variable for each annotations list as we build it\n",
        "image_annotations_train, image_annotations_test, image_annotations_valid = [], [], []\n",
        "\n",
        "# Create blank list for class names\n",
        "class_list = []\n",
        "\n",
        "# read each line, parse it, convert it, put it all back together\n",
        "# then drop it in the appropriate subset\n",
        "with open(annotations_file, \"r\") as f:\n",
        "    reader = csv.reader(f, delimiter=\",\")\n",
        "    for line in reader: \n",
        "        # output we want:\n",
        "        # format: path/to/image.jpg,x1,y1,x2,y2,class_name\n",
        "        # example: /data/imgs/img_001.jpg,837,346,981,456,cow\n",
        "        if 'filename' in line[0]:\n",
        "            # bypassing comments in csv\n",
        "            continue\n",
        "        if '{}' in line[5]:\n",
        "            #bypassing empty images\n",
        "            continue\n",
        "            \n",
        "        filename = line[0]\n",
        "        \n",
        "        # pulling from column named \"region_shape_attributes\"\n",
        "        box_entry = json.loads(line[5])\n",
        "        top_left_x, top_left_y, width, height = box_entry[\"x\"], box_entry[\"y\"], box_entry[\"width\"], box_entry[\"height\"]\n",
        " \n",
        "        if width == 0 or height == 0:\n",
        "            continue\n",
        "            # skip tiny/empty boxes\n",
        "        \n",
        "        # convert from \"top left and width/height\" to \"x and y values at each corner of the box\"\n",
        "        if top_left_x < 0:\n",
        "            top_left_x = 1\n",
        "        if top_left_y < 0:\n",
        "            top_left_y = 1\n",
        "        x1, x2, y1, y2 = top_left_x, top_left_x + width, top_left_y, top_left_y + height \n",
        "        \n",
        "        # pulling from column named \"region_attributes\" to get class names\n",
        "        name = json.loads(line[6])[\"Age Class\"]\n",
        "\n",
        "        # skip unknown class, in this case. Might be useful in other applications though,\n",
        "        # e.g. total object count irrespective of class\n",
        "        if name == \"Unknown\":\n",
        "            continue\n",
        "\n",
        "        # build list of classes as we encounter new names\n",
        "        if name not in class_list:\n",
        "            class_list.append(name)\n",
        "\n",
        "          # create the annotation row\n",
        "        new_row = [filename, x1, y1, x2, y2, name]\n",
        "        \n",
        "        # append the row to the correct subset (training, testing, or validation)\n",
        "        if filename in train_dataset:\n",
        "            image_annotations_train.append(new_row)\n",
        "        elif filename in test_dataset:\n",
        "            image_annotations_test.append(new_row)\n",
        "        else:\n",
        "            image_annotations_valid.append(new_row)\n",
        "\n",
        "ttv_ = list(map(len, [image_annotations_train, image_annotations_test, image_annotations_valid]))\n",
        "ttv = list(map(int, [x/sum(ttv_)*100 for x in ttv_]))\n",
        "print(\"total breakdown of annotations: {n} - {tr}% training set, {t}% testing set, {v}% validation set\".format(tr=str(ttv[0]), t=str(ttv[1]), v=str(ttv[2]), n=ttv_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NwUNk5Pl2VH"
      },
      "source": [
        "### Output annotations.csv and classes.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K_ihMuHl2VH"
      },
      "source": [
        "with open(output_dir + '/annotations_train.csv', 'w', newline='') as fp:\n",
        "    writer = csv.writer(fp)\n",
        "    writer.writerows(image_annotations_train)\n",
        "\n",
        "with open(output_dir + '/annotations_test.csv', 'w', newline='') as fp:\n",
        "    writer = csv.writer(fp)\n",
        "    writer.writerows(image_annotations_test)\n",
        "\n",
        "with open(output_dir + '/annotations_valid.csv', 'w', newline='') as fp:\n",
        "    writer = csv.writer(fp)\n",
        "    writer.writerows(image_annotations_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz1yu_PHl2VI"
      },
      "source": [
        "# this bit uses our class_list (built during annotations processing) to create our classes file\n",
        "# note again that \"unknown\" ambiguous cases have been excluded in this case\n",
        "\n",
        "detection_classes = []\n",
        "\n",
        "for i in range(0, len(class_list)):\n",
        "    detection_classes.append([class_list[i], i])\n",
        "\n",
        "with open(output_dir + '/classes.csv', 'w', newline='') as fp:\n",
        "    writer = csv.writer(fp)\n",
        "    writer.writerows(detection_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKr-mRmkl2VI"
      },
      "source": [
        "#### Zip data folder for download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hJ-GFG2ql2VI",
        "outputId": "2e9c5b0c-0a4c-4281-81bf-92064ea7c7d2"
      },
      "source": [
        "# zip up the output directory into an archive for download\n",
        "import subprocess\n",
        "output_file_name = 'Step_3_{o}'.format(o=output_dir)\n",
        "subprocess.call(['zip', '-r', output_file_name + '.zip', '/content/' + output_dir])\n",
        "\n",
        "from google.colab import files\n",
        "files.download(output_file_name + \".zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_06ab4d85-9e4e-48ce-9896-f911c9bbf8dc\", \"Step_3_RetinaNet_annotations.zip\", 30810)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8kyBoYEl2VI"
      },
      "source": [
        "At the end of this script you should have downloaded and 5 `csv` files (Testing, Training and Validation annotation subsets, the subset list  and the classes list). Drop these all in the google directory so they can be ingested by our CNN code in the next step.\n",
        "\n",
        "Next steps:\n",
        "\n",
        "4) train, refine, and test CNN using VIA annotations and the tiles generated here\n",
        "\n",
        "5) export CNN outputs"
      ]
    }
  ]
}