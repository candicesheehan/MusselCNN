{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Mussel_1_orthomosaic_to_tiles.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/candicesheehan/MusselCNN/blob/main/.ipynb_checkpoints/Mussel_1_orthomosaic_to_tiles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl0scVF_G5VV"
      },
      "source": [
        "# Inspect, Crop/Tile, and Export UAS Imagery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5jd5b4zG5Vd"
      },
      "source": [
        "**Before running this script, create a Google Drive folder with just the orthomosaic you are going to use. You should also know the approximate pixel-length of your target object (here, a large seal) in your mosaic (this will become the `overlap` variable during tiling). The script is expecting a GeoTIFF file, so code tweaking is necessary if your mosaic is not that.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRUtUEXGG5Ve"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/candicesheehan/MusselCNN/blob/master/1_orthomosaic_to_tiles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "#####  <center> Be sure to update this hyperlink above if you clone and want to point to a different GitHub </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP2T0bqXG5Ve"
      },
      "source": [
        "### Connect to our Google Drive folder and pull tif files\n",
        "Note: when you run this it will give you a link that you must click. You must give Google some permissions, then copy a code into a box that comes up in the output section of this code.\n",
        "\n",
        "If customizing this code, you will need to point the `drive_folder` variable to a URL for your shared google drive folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSaExuqeG5Vf"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('mosaic')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "\n",
        "# set variable to the destination google drive folder you want to pull from\n",
        "drive_folder = 'https://drive.google.com/drive/folders/1wuAONrdYYNylyb_ZV2hpd-SrYjk-UXty'\n",
        "\n",
        "# this bit points the code to that google drive folder\n",
        "pointer = str(\"'\" + drive_folder.split(\"/\")[-1] + \"'\" + \" in parents\")\n",
        "\n",
        "file_list = drive.ListFile(\n",
        "    {'q': pointer}).GetList()\n",
        "\n",
        "# this bit pulls all tif files from the directory specified above\n",
        "for f in file_list:\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  if fname.endswith(\".tif\"):\n",
        "    f_ = drive.CreateFile({'id': f['id']})\n",
        "    f_.GetContentFile(fname)\n",
        "    print(\"Pulled file: \" + fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRQTUVzlfWFC"
      },
      "source": [
        "### Identify orthomosaic file from among files in the input directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTz8S3lvihOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ad709f-28c8-487a-f9a0-43653b450225"
      },
      "source": [
        "# use this variable to set input directory\n",
        "input_dir = local_download_path\n",
        "\n",
        "orthomosaic_file = []\n",
        "  \n",
        "for fname in os.listdir(input_dir):\n",
        "  candidate_file = \"{i}/{f}\".format(i=input_dir, f=fname)\n",
        "  os.stat(candidate_file)\n",
        "  # if the file is a *.tif and larger than 100 mb we label it the orthomosaic\n",
        "  if os.stat(candidate_file).st_size > 10**8 :\n",
        "    # if there are multiple orthomosaic files detected we spit an error\n",
        "    if len(orthomosaic_file) != 0:\n",
        "        raise Exception(\"more than one orthomosaic file identified based on size and type\")\n",
        "    orthomosaic_file = candidate_file\n",
        "    print(\"orthomosaic identified as \" + orthomosaic_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "orthomosaic identified as mosaic/2015_02_02_hay_island_flight03_s110rgb_jpeg_mosaic_group1.tif\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az4U54aCG5Vg"
      },
      "source": [
        "### Set up the python environment and prep some variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Flzb9-t9G5Vg"
      },
      "source": [
        "!pip install rasterio\n",
        "!pip install pyproj\n",
        "from PIL import Image\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "import json\n",
        "import csv\n",
        "import rasterio\n",
        "import matplotlib\n",
        "import folium\n",
        "from pyproj import Proj, transform\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "Image.MAX_IMAGE_PIXELS = 100000000000\n",
        "\n",
        "dataset = rasterio.open(orthomosaic_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y37DXCxxG5Vh"
      },
      "source": [
        "### Examine the metadata of the orthomosiac\n",
        "This is mostly for checking/viewing info, but it does also set up some critical variables for later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr_PTAq0G5Vh"
      },
      "source": [
        "# what is the name of this image\n",
        "print('Image filename: {n}\\n'.format(n=dataset.name))\n",
        "\n",
        "# How many bands does this image have?\n",
        "num_bands = dataset.count\n",
        "print('Number of bands in image: {n}\\n'.format(n=num_bands))\n",
        "\n",
        "# How many rows and columns?\n",
        "rows, cols = dataset.shape\n",
        "print('Image size is: {r} rows x {c} columns\\n'.format(r=rows, c=cols))\n",
        "\n",
        "# Does the raster have a description or metadata?\n",
        "desc = dataset.descriptions\n",
        "metadata = dataset.meta\n",
        "\n",
        "print('Raster description: {desc}\\n'.format(desc=desc))\n",
        "\n",
        "# What driver was used to open the raster?\n",
        "driver = dataset.driver\n",
        "print('Raster driver: {d}\\n'.format(d=driver))\n",
        "\n",
        "# What is the raster's projection?\n",
        "proj = dataset.crs\n",
        "print('Image projection:')\n",
        "print(proj, '\\n')\n",
        "\n",
        "# What is the raster's \"geo-transform\"\n",
        "gt = dataset.transform\n",
        "\n",
        "print('Image geo-transform:\\n{gt}\\n'.format(gt=gt))\n",
        "\n",
        "print('All raster metadata:')\n",
        "print(metadata)\n",
        "print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-9mOoThG5Vh"
      },
      "source": [
        "### Plot the image\n",
        "Also mostly for viewing and confirming that things look appropriate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWe6pXyQG5Vi"
      },
      "source": [
        "from rasterio.plot import show\n",
        "from rasterio.windows import Window\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15,15))\n",
        "\n",
        "show(dataset.read((1,2,3), window=Window(5000, 5000, 2000, 2000)), transform=dataset.transform, ax=ax)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xQv6M5RG5Vi"
      },
      "source": [
        "# plot the whole orthomosaic\n",
        "fig, (axrgb) = plt.subplots(1, figsize=(15,15))\n",
        "show(dataset.read(), transform=dataset.transform, ax=axrgb)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgmGGA-HG5Vi"
      },
      "source": [
        "### Visualize on the Map\n",
        "Again, mostly a disgnostic check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ3R5A2VG5Vi"
      },
      "source": [
        "dataset.crs\n",
        "\n",
        "# Project all longitudes, latitudes\n",
        "utm_tl = dataset.transform * (0, 0)\n",
        "utm_br = dataset.transform * (dataset.width, dataset.height)\n",
        "utm_center = dataset.transform * (dataset.width // 2, dataset.height // 2)\n",
        "\n",
        "positions = dataset.transform * (0, 0), dataset.transform * (dataset.width, 0), dataset.transform * (dataset.width, dataset.height), dataset.transform * (0, dataset.height),\n",
        "\n",
        "p1 = Proj(dataset.crs)\n",
        "p2 = Proj(proj='latlong',datum='WGS84')\n",
        "tl_long, tl_lat = transform(p1, p2, utm_tl[0], utm_tl[1])\n",
        "br_long, br_lat = transform(p1, p2, utm_br[0], utm_br[1])\n",
        "center_long, center_lat = transform(p1, p2, utm_center[0], utm_center[1])\n",
        "\n",
        "longs, lats = transform(p1, p2, np.array(positions)[:,0],np.array(positions)[:,1])\n",
        "points = list(zip(lats, longs))\n",
        "print(tl_long,tl_lat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td8yHMoFG5Vj"
      },
      "source": [
        "m = folium.Map(location=[center_lat, center_long])\n",
        "\n",
        "tooltip=\"Raster\"\n",
        "#folium.Marker([tl_lat, tl_long], popup='<i>Raster Top Left</i>', tooltip=tooltip).add_to(m)\n",
        "#folium.Marker([br_lat, br_long], popup='<i>Raster Bottom right</i>', tooltip=tooltip).add_to(m)\n",
        "#folium.Marker([center_lat, center_long], popup='<i>Raster Center</i>', tooltip=tooltip).add_to(m)\n",
        "\n",
        "folium.Polygon(points, \n",
        "               tooltip=tooltip, \n",
        "               popup='Laurelhurst Park',\n",
        "               color='#3186cc',\n",
        "               fill=True,\n",
        "               fill_color='#3186cc').add_to(m)\n",
        "\n",
        "#folium.PolyLine(points, color=\"red\", weight=100, opacity=1).add_to(m)\n",
        "\n",
        "m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyPTIx4yG5Vj"
      },
      "source": [
        "### Crop the Image into Tiles\n",
        "This section breaks up the orthomosaic image into tiles. <b> It is important to set the `overlap` variable to the pixel-length of at least 1 target object (here, a seal) </b> in case the tiling process \"cuts up\" some of your objects into undetectable shapes at the edges. Adequate `overlap` ensures that a target object that gets \"cut up\" on one edge, will be intact in an adjacent image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNK3MLzVG5Vj"
      },
      "source": [
        "# set tile size (pixels): this is dictated by what constitutes a managable filesize for processing\n",
        "tile_height = tile_width = 1000\n",
        "\n",
        "# set overlap: this should equal 1–2x the pixel-length of our feature of interest\n",
        "overlap = 80\n",
        "\n",
        "stride = tile_height - overlap\n",
        "start_num=0\n",
        "\n",
        "def crop(orthomosaic_file, tile_height, tile_width, stride, img_dict, prj_name):\n",
        "    im = Image.open(orthomosaic_file) \n",
        "    img_width, img_height = im.size\n",
        "    print(im.size)\n",
        "    print(img_width * img_height / (tile_height - stride) / (tile_width - stride))\n",
        "    count = 0\n",
        "    for r in range(0, img_height, stride):\n",
        "        for c in range(0, img_width, stride):\n",
        "            #tile = im[r:r+100, c:c+100]\n",
        "            box = (c, r, c+tile_width, r+tile_height)\n",
        "            top_pixel = [c,r]\n",
        "            count += 1\n",
        "            yield im.crop(box), top_pixel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVPkKWxtG5Vj"
      },
      "source": [
        "### Split the image up into `height` × `width` patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-nGX8pwG5Vk"
      },
      "source": [
        "prj_name = orthomosaic_file.split(\".\")[0].split(\"/\")[-1]\n",
        "img = Image\n",
        "img_dict = {}\n",
        "\n",
        "# use this variable to set output directory\n",
        "output_dir = 'tiled_data'\n",
        "try:\n",
        "  os.makedirs(output_dir)\n",
        "except: pass\n",
        "\n",
        "# create the dir if it doesn't already exist\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# break it up into crops\n",
        "for k, box_w_point in enumerate(crop(orthomosaic_file, tile_height, tile_width, stride, img_dict, prj_name), start_num):\n",
        "    img=Image.new('RGB', (tile_height, tile_width), (255, 255, 255))\n",
        "    img.paste(box_w_point[0])\n",
        "    image_name = prj_name + \"---%s.png\" % k\n",
        "    print(image_name)\n",
        "    corner1, corner2, corner3, corner4 = img.load()[0, 0], img.load()[0, tile_height-1], img.load()[tile_width-1, tile_height-1], img.load()[tile_width-1, 0]\n",
        "    if corner1 == corner2 == corner3 == corner4 == (0, 0, 0):\n",
        "      print(\"empty tile, skipped\")\n",
        "      continue\n",
        "    img_dict[image_name] = box_w_point[1]\n",
        "    path=os.path.join(output_dir, image_name)\n",
        "    img.save(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csgKsaHfG5Vk"
      },
      "source": [
        "### Create a .json file with all image names and geospatial metadata\n",
        "This is important for storing how the tiles fit together, we will need this later to stitch our detections back together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXkFpMWBG5Vk"
      },
      "source": [
        "full_dict = {\"image_name\" : orthomosaic_file,\n",
        "            \"image_locations\" : img_dict,\n",
        "             \"crs\" : str(dataset.crs)\n",
        "            }\n",
        "json_output = output_dir + '/spatial_data.json'\n",
        "\n",
        "with open(json_output, 'w') as fp:\n",
        "    json.dump({\"orthomosaic_file\":orthomosaic_file.split(\"/\")[-1], \"tile_height\":tile_height, \"tile_width\":tile_width, \"tile_pointers\":full_dict}, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNinAA7nG5Vk"
      },
      "source": [
        "### Zip data folder for download\n",
        "This section downloads the tiles and `json` file describing the spatial data for each tile image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJhLcbz_G5Vk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9a233d7-1573-4a6f-974f-34f39427dead"
      },
      "source": [
        "# zip up the tiles output directory into an archive for download\n",
        "output_file_name = 'Step_1_{o}'.format(o=output_dir)\n",
        "import subprocess\n",
        "subprocess.call(['zip', '-r', output_file_name + '.zip', '/content/' + output_dir])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sbTVQGUG5Vl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "42a966c6-1a3b-4934-fb01-1938d7bbaed8"
      },
      "source": [
        "# download the zipped archive of your outputs from this code\n",
        "from google.colab import files\n",
        "files.download(output_file_name + \".zip\")\n",
        "\n",
        "#alternatively you can manually download the zipped archive from the Colab browser panel interface"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_81091f83-447a-4cf9-9858-10476704c74b\", \"Step_1_tiled_data.zip\", 314444914)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "190041_iG5Vl"
      },
      "source": [
        "##### At the end of this script you should have downloaded all tile files and the spatial_data.json files. The tiles set should be ready for annotation in VIA to create training data. When you load the script to train the CNN, you will need the tiles and `spatial_data.json` file from this script (+ the `json` file from VIA, + annotation `csv` files that have been converted to RetinaNet format)\n",
        "\n",
        "Next steps:\n",
        "\n",
        "2) create annotations in VIA, save `csv` output\n",
        "\n",
        "3) convert annotations from VIA format to RetinaNet format, with Training, Testing, and Validation subsets\n",
        "\n",
        "4) train, refine, and test CNN using VIA annotations and the tiles generated here, produce precision metrics\n",
        "\n",
        "5) export CNN outputs, manual annotations, and tile footprints as shapefiles\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP8TS-5H2GEi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "475a3ba0-c6c1-4971-f091-5043e29bfe8e"
      },
      "source": [
        "# if you just want to download the json file (e.g. for troubleshooting), click this bit of code:\n",
        "from google.colab import files\n",
        "files.download(\"/content/\" + output_dir + \"/spatial_data.json\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_755c225d-018c-428d-b5b3-39ca968c8b37\", \"spatial_data.json\", 21072)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}